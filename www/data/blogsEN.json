[
  {
    "id": "1",
    "title": "My take on the AI surge",
    "hook": "A brief look at the current explosion of AI technologies.",
    "image": "images/blog-thumb-1.png",
    "date": "2025-08-06",
    "content": "I remember when I first discovered I wanted to become an AI engineer. It was back in 2017, when a fiction author described what he called a \"bottom-up\" AI, an algorithm that could mimic human learning patterns and develop the same way a baby would. I thought that was the coolest thing ever and immediately wanted to help bring something like that into reality.\n\n So I started digging into how AI works, learning about algorithms, their uses, and their limits. And those limits are something I feel aren’t advertised enough today.\n\n Then, in late 2022, ChatGPT launched. That hit the world like a meteor. It was the first time in years that a piece of technology captured mainstream attention on the scale of the iPhone. Along with the hype came a wave of problems: news segments, influencer hot takes, and endless podcast episodes featuring “experts”, often big public figures like OpenAI’s CEO Sam Altman or billionaire Elon Musk.\n\n The questions they faced were usually basic: How does an LLM work? What kind of work can it actually do? But then came the big one: When will we achieve AGI? \n\n If you were the CEO of a company whose lifeline is investor funding, would you admit AGI is never coming, or would you sell the dream to keep the hype alive? Exactly.\n\n I think the public is being swept up in a mix of hype and fear. Fear of AI taking over the world. And while yes, AI will replace some jobs, just like tractors did on farms. I don’t believe we’re anywhere close to an all-knowing, ever-growing robot intelligence ruling society."
   },
  {
    "id": "2",
    "title": "A look into the video game industry's atmosphere",
    "hook": "Why consumers matter and how their preferences shape the market.",
    "image": "images/blog-thumb-3.png",
    "date": "2025-08-20",
    "content": "Mortal Kombat, Pokémon, The Legend of Zelda, Halo, World of Warcraft, Call of Duty.\n\nI grew up with those games, and so did many people of my generation. They embodied something game developers understood back then: the key to making a great video game was asking, “What do players dream of doing?”\n\nUnfortunately, we’ve entered an era where that question no longer drives the industry. Instead, the focus has shifted to monetization, artificially stretched lifespans, and even loopholes that strip away ownership. If there’s a way to squeeze more out of the consumer, big publishers will find it. Battle passes, reselling the same game every year like EA Sports titles, shutting down live-service servers, daily missions, and even gambling mechanics, all of these tactics exist to take every possible dollar from an IP.\n\nVideo games used to sell us dreams. You could live through a hero’s journey with no strings attached. Today, too often, players feel the need to fight back against these practices through boycotts, online outrage, and, unfortunately, piracy."
   },
  {
    "id": "3",
    "title": "Why LLMs don't actually think",
    "hook": "An oversimplified view of the limitations of large language models.",
    "image": "images/blog-thumb-2.png",
    "date": "2025-08-13",
    "content": "There’s a misconception going around that LLMs are capable of \"thinking.\" It’s an easy mistake to make. And I won't be the one to correct people in a casual conversation, but here, I will.\n\nLLMs are algorithms, mathematical systems that produce results based on probabilities. They work by assigning values to words based on how often those words appear near each other in their training data.\n\nFor example, if you ask a human what a storefront needs, they’ll picture stores they’ve seen, recall personal experiences, and choose components based on utility door, windows, signs, lighting, etc. An LLM, on the other hand, doesn’t “picture” anything. It looks at the statistical patterns surrounding the word “storefront” and picks the words most likely to follow.\n\nThat means it could easily make a choice that’s technically correct in language but oblivious in reality. It doesn’t understand that a door serves a functional purpose; it only knows “door” often appears when people describe storefronts.\n\nLLMs also lack common sense because they have no personal experiences to draw from. There’s no chain of reasoning in the human sense, just statistical pattern matching.\n\nHallucinations are one of the clearest signs of this limitation. When the model doesn’t have enough information, it doesn’t admit “I don’t know.” Instead, it guesses, pulling together words that fit the pattern even if the result is wrong. This is why you might see AI inventing books, authors, or events that never existed.\n\nThe good news is hallucinations are one of the most fixable issues with AI. With better training data and systems we can reduce them significantly.\n\nLLMs are great tools for generating language, but they’re not thinkers. They don’t understand the world, form ideas, or reason through problems the way humans do. They are advanced pattern recognition machines. That is both their strength and their biggest limitation."
    },
  {
    "id": "4",
    "title": "How I manage making working on code fun",
    "hook": "Habits and personnal strategies for enjoyable coding.",
    "image": "images/blog-thumb-4.png",
    "date": "2025-08-27",
    "content": "I believe every job eventually loses its spark. That’s just basic human psychology. When your brain is exposed to the same task long enough, it stops feeling exciting, no matter how fun it was at the beginning. That’s why you have to make your own fun by adding little routines into your day that bring a breath of fresh air. It’s for that reason people enjoy things like Wordle, sudoku, or crosswords: the activity changes daily, is easy to insert in your day to day, and breaks the monotony.\n\nI’ve found my own ways to keep coding fresh and make tasks more unique to tackle, which, in turn, improves both my mood and productivity. For me, it all starts with the environment. I use an application that lets me set animated wallpapers, and I love swapping them out every other week to give my screens a new look. I also use other small tools to personalize my desktop. It may seem trivial, but taking two minutes to choose a new “coding companion” for the week makes sitting down at my computer feel less routine.\n\nThe other part of my environment is sound. I rotate between ambient tracks and music depending on the day. Rain, lo-fi, or even thunderstorms are all sounds I enjoy having in my ears while I’m untangling a sneaky bug in the codebase. Sometimes it’s less about the music itself and more about creating an atmosphere that makes me want to keep going.\n\nIn the end, making coding fun isn’t about big changes or what you are working on, it’s about the small details that keep your mind curious and your work enjoyable."
  }
]